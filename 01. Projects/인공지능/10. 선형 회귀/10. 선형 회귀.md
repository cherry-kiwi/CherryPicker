# 선형 회귀
- 지도 학습
	- 회귀(regression): 연속적인 값 예측
		- ex) 주택 면적 고려하여 주택 가격 예측하는 것
	- 분류(classification): 입력값을 카테고리로 분류
		- ex) 주어진 이미지가 고양이인지 강아지인지 판별
![[Pasted image 20231014174753.png]]

## 회귀
- 데이터들을 2차원 공간에 찍은 후, 데이터를 잘 설명할 수 있는 직선 or 곡선을 찾는 문제
- $y=f(x)$ 에서 출력 y가 실수고, 입력 x도 실수 일 때 함수 $f(x)$ 를 예측하는 것
- ex) 주식 가격 예측, 온도 변화, 전력 수요 변동
## 선형 회귀
- 직선 모델을 사용하여 회귀 문제 푸는 것
- 부모의 키와 자녀의 키의 관계, 공부 시간과 학점과의 관계,  CPU 속도와 프로그램 실행 시간 예측
### 선형 회귀 소개
$$f(x) = mx + b$$
- 입력 데이터를 가장 잘 설명하는 직선의 기울기($m$)와 절편($b$)을 찾는 문제
- 우리가 제어할 수 있는 값: 기울기($m$), 절편($b$)
- 머신러닝에서는 기울기($m$) = 가중치($w$) / 절편($b$) = 바이어스($b$)
$$f(x) = wx + b$$
### 선형 회귀 종류
1. 단순 선형 회귀: 독립 변수($x$)가 하나인 선형 회귀
$$f(x) = wx + b$$
- $x, y$는 학습 데이터 / $f(x)$는 우리의 예측
2. 다중 선형 회귀
$$f(x,y,z) = w_0 + w_1x + w_2y + w_3z$$
- $w_0, w_1x, w_2y, w_3z$는 계수 or 가중치. 모델이 학습하려고 하는 매개 변수

### 선형 회귀 원리
![[Pasted image 20231016212753.png]]
- 선형 회귀에선 이 기울기 중 학습 데이터와 가장 잘 맞는 하나의 직선 선택하게 됨
- 가장 잘 맞는 직선: 데이터와 직선의 간격이 작을수록 잘 맞음
	- 간격은 음수일 수 있으니 제곱을 하는게 좋음
	- 간격의 제곱을 모두 합한 값 = 손실 함수(loss function) 혹은 비용 함수(cost function)
- 훈련 데이터 세트가 ($x_1, y_1$), ($x_2, y_2$), ($x_3, y_3$) 일 때, 손실은 다음과 같이 표현
- $$Loss=\frac{1}{3}((f(x_1)-y_1)^2+(f(x_2)-y_2)^2+(f(x_3)-y_3)^2$$
- 또는 $$Loss(w,b)=\frac{1}{n}\Upsigma$$