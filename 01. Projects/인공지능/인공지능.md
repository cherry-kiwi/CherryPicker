1. 인공지능: **인간의 인지적인 기능을 흉내내 문제를 해결하기 위해 학습하고 이해하는 기계(컴퓨터)**
2. 인공지능 급격한 발전을 이룬 주요 세가지 요소
	1. 빅데이터: **디지털 환경에서 발생하는 대량의 모든 데이터**
	2. 고속 컴퓨터: **여러 서버에 걸쳐 복잡한 계산을 병렬로 고속 처리하는 컴퓨터**
	3. 딥러닝: **다층 신경망을 사용하는 딥러닝의 발전이 인공지능의 혁신을 이끎**
3. 인공지능 vs 머신러닝 vs 딥러닝
	1. 인공지능: **인간처럼 학습하고 추론하는 프로그램 연구**
	2. 머신러닝: **인공지능의 한 분야로서 프로그래밍 없이 스스로 학습하는 프로그램 연구**
	3. 딥러닝: **머신러닝의 한 분야로서 인공신경망 등을 사용해 빅데이터로부터 학습하는 프로그램 연구**
4. 학습 3가지 형태 (지도학습, 비지도학습, 강화학습)
	1. 지도학습: **입력을 출력에 매핑하는 일반적인 규칙을 학습하는 것**
	2. 비지도학습: **외부에서 정답이 안주어지고, 알고리즘이 스스로 데이터에서 패턴을 발견하는 학습**
	3. 강화학습: **보상 및 처벌의 형태로 학습 데이터가 주어지는 것**
5. 회귀와 분류 비교설명 / 선형회귀와 분류 유사성 설명
	1. 회귀: **입출력이 연속적인 수치값**
	2. 분류: **입력을 2개 이상의 부류로 나누는 것**
	3. 유사성: **모두 연속적이지 않다**
6. 머신러닝 알고리즘의 성능평가 방법 2가지
	1. 정확도 = **올바르게 분류한 샘플수  / 전체 샘플 수**
	2. 혼동행렬: **학습된 머신러닝 시스템이 예측을 하면서 얼마나 혼동하고 있는지 나타내는 행렬**
7. 기계학습에서 선형회귀에 대해 다음에 답하라
	1. n개의 데이터($x_i,y_i$)에 대해 구하고자 하는 선형회귀 함수를 $f(x)=wx+b$라 할 때,
	   MSE(평균제곱오차). MAE(평균절대오차), 손실(비용)함수 E를 정의하라.
	   $E=\frac{1}{n}\sum^{n}_{i=1}(f(x_i)-y_i)^2=\frac{1}{n}\sum^{n}_{i=1}(f(wx_i+b)-y_i)^2$
	   $MSE=\frac{1}{n}\sum^{n}_{i=1}(y_i-\hat{y_i})^2$
	   $MAE=\frac{1}{n}\sum^{n}_{i=1}|x_i-x|$
	2. 위의 MSE에 대해 비용함수를 w에 대해 미분하라.
	   dE/db=$\frac{1}{n}\sum^{n}_{i=1}((wx_i+b)-y_i)(1)=\frac{2}{n}\sum^{n}_{i=1}((wx_i+b)-y_i)$
	3. 비용함수를 b에 대해 미분하라.
	   dE/db=$\frac{2}{n}((wx_i+b)-y_i)(1)=\frac{2}{n}\sum^{n}_{i=1}((wx_i+b)-y_i)$
	4. 경사하강법: 한 지점에서 출발해 최저값에 닿길 바라며 점점 이동하는 방법
	   w, b 업데이트 수식:
	   $w=w-0.01\times \frac{dE}{dW}$
	   $b=b-0.01\times \frac{dE}{dW}$
	5. 학습률: **한번에 매개변수를 변경하는 비율**, 계산을 여러번 해야 최저값에 도달할 수 있음
8. 위 문제에서 2개의 데이터 (1,2), (2,3) 대해 선형 회귀 함수 구하려한다.
	1. 파이썬 프로그래밍
```
x=np.array([1.0, 2.0])           # x 입력데이터
y=np.array([2.0, 3.0])           # y 입력데이터
lrate=0.01                       # 학습률
n=float(len(x))
epoches=100
w, b = 0                         # w, b 설정

for i in range(epoches):
	y_pred = w * X + b           # 직선의 방정식에 대입
	dw = (2/n)*sum(X*(y_pred-y)) # MSE 미분
	db = (2/n)*sum(y_pred-y)     # MSE 미분
	w = w - lrate * dw           # w 업데이트 (경사하강법에 의한)
	b = b - lrate * db           # b 업데이트 (경사하강법에 의한)
```
 ㅇ 
		2.  초기 w=0.5, b=1 일 때, 경사하강법에 의해 w, b를 한번만 업데이트 한 값은? (학습률 0.1)
		   ![[Pasted image 20231022185801.png]]

9. XOR 논리연산을 수행하는 퍼셉트론 신경망 모델에 대해 다음에 답하라.
	1. 진리표
	   | A   | B   | XOR |
	   | 0   | 0   | 0   |
	   | 0   | 1   | 1   |
	   | 1   | 0   | 1   |
	   | 1   | 1   | 0   |
	   
	2. 2차원 좌표계로 표시
	   ![[Pasted image 20231022180640.png|200]]
	3. 퍼셉트론 모델 그려라
	   ![[Pasted image 20231022180712.png|200]]
	4. 입력에 대한 출력을 수식으로 적어라
	   $x_1=0, x_2=0$  일 때, 
	   $y_1$의 출력: $0.6*0+0.6*0-1.0=-1.0$
	   $y_2$의 출력: $1.1*0+1.1*0-1.0=-1.0$
	   $y$의 출력: $-2.0*0+1.1*0-1.0=-1.0$
	5. 학습해야 할 파라미터의 전체 개수: **6개(화살표 개수)**
	6. 위 모델로 XOR문제 해결 가능? **YES. 입력층과 출력층 사이에 은닉층을 둔 다층 퍼셉트론 구조라**
5. 위 4번을 파이썬으로 구현
```
# step 함수(활성화 함수)
def step(x):
	if x > 0: return 1
	else: return 0

# 순방향 전파 계산
def perceptron_fit(x, Y, epoches=10):
	lrate=0.02
	global W                   # w 전역변수 설정
	
	for i in range(epoches):   
		y_out=np.dot(x[i], w)  # 입력벡터와 행렬의 내적 구함
		y_pred=step(y_out)     # 활성화 함수 적용
		error = Y[i]-y_pred    # 오차 계산
		W+=lrate*error*x[i]    # 가중치 업데이트
```
11. 위 perceptron_predict(x)를 파이썬으로 구현
```
global W

for x in X:
	print(x[0], x[1], "->", step(np.dot(x, W)))
```